{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMQUH6f/wxd8ccC/llBlxy/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swalehaparvin/HuggingFace/blob/main/Hugging_face.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "peeYGg7lROko"
      },
      "outputs": [],
      "source": [
        "!pip install huggingface_hub\n",
        "import torch\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
        "\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
        "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
        "\n",
        "inputs = tokenizer(\"Hello, I like america\", return_tensors=\"pt\")\n",
        "with torch.no_grad():\n",
        "    logits = model(**inputs).logits\n",
        "\n",
        "predicted_class_id = logits.argmax().item()\n",
        "model.config.id2label[predicted_class_id]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "!pip install huggingface_hub\n",
        "text = \"AI-powered robots assist in complex brain surgeries with precision.\"\n",
        "\n",
        "# Create the pipeline\n",
        "classifier = pipeline(task=\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
        "\n",
        "# Create the categories list\n",
        "categories = [\"politics\", \"science\", \"sports\"]\n",
        "\n",
        "# Predict the output\n",
        "output = classifier(text,categories)\n",
        "\n",
        "# Print the top label and its score\n",
        "print(f\"Top Label: {output['labels'][0]} with score: {output['scores'][0]}\")"
      ],
      "metadata": {
        "id": "hSjVJGK-k6Kk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate and display the dataset size in megabytes"
      ],
      "metadata": {
        "id": "DKr5lZwF0mfQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the function to load dataset metadata\n",
        "from datasets import load_dataset_builder\n",
        "# Initialize the dataset builder for the MMLU-Pro dataset and Display dataset metadata\n",
        "reviews_builder = load_dataset_builder(\"TIGER-Lab/MMLU-Pro\")\n",
        "print(reviews_builder.info)\n",
        "# Calculate and print the dataset size in MB\n",
        "dataset_size_mb = reviews_builder.info.dataset_size / (1024 ** 2)\n",
        "print(f\"Dataset size: {round(dataset_size_mb, 2)} MB\")\n"
      ],
      "metadata": {
        "id": "OvnvghEa0nVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Manipulating datasets\n",
        "There will likely be many occasions when you will need to manipulate a dataset before using it within a ML task. Two common manipulations are filtering and selecting (or slicing). The dataset is already loaded for you under wikipedia.\n",
        "Filter the dataset for rows with the term \"football\" in the text column and save as filtered.\n",
        "Select a single example from the filtered dataset and save as example."
      ],
      "metadata": {
        "id": "pWfiSGc80r8n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "wikipedia = load_dataset(\"wikipedia\", \"20220301.en\", split=\"train\")\n",
        "# Filter the documents\n",
        "filtered = wikipedia.filter(lambda row: \"football\" in row[\"text\"])\n",
        "# Create a sample dataset\n",
        "example = filtered.select(range(1))\n",
        "print(example[0][\"text\"])"
      ],
      "metadata": {
        "id": "Eoj4LKKj0uyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Grammatical correctness\n",
        "Text classification is the process of labeling an input text into a pre-defined category. This can take the form of sentiment - positive or negative - spam detection - spam or not spam - and even grammatical errors.\n",
        "Explore the use of a text-classification pipeline for checking an input sentence for grammatical errors.\n"
      ],
      "metadata": {
        "id": "akZRSBOi1FL7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a pipeline for grammar checking\n",
        "grammar_checker = pipeline(\n",
        "  task=\"text-classification\",\n",
        "  model=\"abdulmatinomotoso/English_Grammar_Checker\"\n",
        ")\n",
        "# Check grammar of the input text\n",
        "output = grammar_checker(\"I will walk dog\")\n",
        "print(output)"
      ],
      "metadata": {
        "id": "TSIN5NAz1G0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question Natural Language Inference\n",
        "Another task under the text classification umbrella is Question Natural Language Inference, or QNLI. This checks if a premise contains enough information to answer a posed question, determining whether the answer can be found in the given text.\n",
        "Create a text classification QNLI pipeline using the model \"cross-encoder/qnli-electra-base\" and save as classifier.\n",
        "Use this classifier to determine if the text provides enough information to answer the question."
      ],
      "metadata": {
        "id": "AI8S_doQ1O11"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the pipeline\n",
        "classifier=pipeline(task=\"text-classification\", model=\"cross-encoder/qnli-electra-base\")\n",
        "# Predict the output\n",
        "output = classifier(\"Where is the capital of France?, Brittany is known for its stunning coastline.\")\n",
        "print(output)"
      ],
      "metadata": {
        "id": "wkExL8_41NkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dynamic category assignment\n",
        "Dynamic category assignment enables a model to classify text into predefined categories, even without prior training for those categories.\n",
        "Build the pipeline and save as a classifier.\n",
        "Create a list of the labels - \"politics\", \"science\", \"sports\" - and save as categories.\n",
        "Predict the label of text using the classifier and predefined categories."
      ],
      "metadata": {
        "id": "qYs7PWno1quw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"AI-powered robots assist in complex brain surgeries with precision.\"\n",
        "# Create the pipeline\n",
        "classifier = pipeline(task=\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
        "# Create the categories list\n",
        "categories = [\"politics\", \"science\", \"sports\"]\n",
        "# Predict the output\n",
        "output = classifier(text,categories)\n",
        "# Print the top label and its score\n",
        "print(f\"Top Label: {output['labels'][0]} with score: {output['scores'][0]}\")"
      ],
      "metadata": {
        "id": "Y_jhqSZP1sIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summarizing long text\n",
        "Summarization reduces large text into manageable content, helping readers quickly grasp key points from lengthy articles or documents.\n",
        "There are two main types: extractive, which selects key sentences from the original text, and abstractive, which generates new sentences summarizing main ideas."
      ],
      "metadata": {
        "id": "MnLfgLWz1xWq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the summarization pipeline\n",
        "summarizer = pipeline(task=\"summarization\", model=\"cnicu/t5-small-booksum\")\n",
        "# Summarize the text\n",
        "summary_text = summarizer(text)\n",
        "# Compare the length\n",
        "print(f\"Original text length: {len(text)}\")\n",
        "print(f\"Summary length: {len(summary_text[0]['summary_text'])}\")"
      ],
      "metadata": {
        "id": "2hp5tATy10fv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using min_length and max_length\n",
        "The pipeline() function, has two important parameters: min_length and max_length. These are useful for adjusting the length of the resulting summary text to be short, longer, or within a certain number of words."
      ],
      "metadata": {
        "id": "chagl2Ba2TcJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a short summarizer\n",
        "short_summarizer = pipeline(task=\"summarization\", model=\"cnicu/t5-small-booksum\", min_length=1, max_length=10)\n",
        "# Summarize the input text\n",
        "short_summary_text = short_summarizer(text)\n",
        "# Print the short summary\n",
        "print(short_summary_text[0][\"summary_text\"])\n",
        "# Repeat for a long summarizer\n",
        "long_summarizer = pipeline(task=\"summarization\", model=\"cnicu/t5-small-booksum\", min_length=50, max_length=150)\n",
        "long_summary_text = long_summarizer(text)\n",
        "# Print the long summary\n",
        "print(long_summary_text[0][\"summary_text\"])"
      ],
      "metadata": {
        "id": "E0ZDxv5o2WL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4ZduoKOG2m1f"
      }
    }
  ]
}